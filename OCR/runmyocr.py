# -*- coding: utf-8 -*-
"""runMyOCR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13EPuM0t1demTO5fYf6KK7RmBHqn2FvxT
"""

import numpy as np
from sklearn.metrics import confusion_matrix
from scipy.spatial.distance import cdist
from skimage.measure import label, regionprops, moments,moments_central, moments_normalized, moments_hu
from skimage import io, exposure, feature, filters, img_as_float
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle
import pickle
from skimage.morphology import dilation, erosion, square, opening, closing, disk
from skimage.filters import threshold_otsu

#normalizes a features list
def normalize(features):
    #convert the list into a array using numpy fucntion
    features_array = np.array(features)
    means = np.mean(features_array, axis=0)

    stds = np.std(features_array, axis=0)
    standardized_features = (features_array - means) / stds
    return standardized_features, stds, means
#----------------------------------------------------------------
#reads and binarize a image
# def read_and_binarize(img_path, th):
#   img = io.imread(img_path);
#   img_binary = (img < th).astype(np.double)

#   return img_binary

def read_and_binarize(img_path, th, use_edge_detection=True, use_blur=True):
  img = io.imread(img_path)

  if use_blur:
        # Apply Gaussian blur
        sigma_value = 1  # This value can be adjusted as needed
        img = filters.gaussian(img, sigma=sigma_value)

  if use_edge_detection:

      otsu_thresh = threshold_otsu(img)

      # Apply Canny edge detection
      edges = feature.canny(img, low_threshold=otsu_thresh*.5, high_threshold=otsu_thresh)
      img_binary = edges.astype(np.double)
  else:

       img_binary = (img < th).astype(np.double)

  return img_binary



#constructs the training features and char label databases
def training_data(img_path, Display = False):
  features = []
  char_labels = []

  for path in img_path:
    #----------------------------------------------------------------
    # io.imshow(img)
    # plt.title('Original Image')
    # io.show()
    #----------------------------------------------------------------
    binary_thresh = 200
    noise_thres = 8

    img_binary = read_and_binarize(path, binary_thresh)
    #----------------------------------------------------------------
    # io.imshow(img_binary)
    # plt.title('Binary Img')
    # io.show()
    selem = square(2)
    img_binary = dilation(img_binary, selem)


    #-----------------------------------------------------------------
    img_label = label(img_binary, background = 0)
    # io.imshow(img_label)
    # plt.title("labled Img")
    # io.show()

    # print(np.amax(img_label))

    regions = regionprops(img_label)
    io.imshow(img_binary)

    ax = plt.gca()
    #------------------------------------------------------
    #features =  process_features(img_binary,regions,th)
    for props in regions:
      minr, minc, maxr, maxc = props.bbox
      ax.add_patch(Rectangle((minc, minr), maxc - minc, maxr - minr, fill=False, edgecolor='red', linewidth=1))
      if (maxr - minr) > noise_thres and (maxc - minc) > noise_thres:
        roi = img_binary[minr:maxr, minc:maxc]
        m = moments(roi)
        cc = m[0, 1] / m[0, 0]
        cr = m[1, 0] / m[0, 0]
        mu = moments_central(roi, center=(cr, cc))
        nu = moments_normalized(mu)
        hu = moments_hu(nu)
        features.append(hu)
        char_labels.append(ord(path[0]) - ord('a') + 1 )

    ax.set_title('Bounding box')
    io.show()
    num_components = np.amax(img_label)
    print(f"Number of Connected Components in {path}: {num_components}")

  normalized_features, std, mean = normalize(features)
  return normalized_features, char_labels, std, mean

def recongnition_training(normalized_features, char_labels):

  D = cdist(normalized_features, normalized_features)
  D_index = np.argsort(D, axis=1)
  correct_matches = 0

  Ypred = []

  for i in range(len(char_labels)):

      nearest_neighbor_index = D_index[i, 1]
      predicted_labels = char_labels[nearest_neighbor_index]
      Ypred.append(predicted_labels)


      if char_labels[i] == predicted_labels:
          correct_matches += 1

  accuracy = correct_matches / len(normalized_features)
  print(f"Accuracy on the training data: {accuracy * 100}%")

  # io.imshow(D)
  # plt.title('Distance Matrix')
  # io.show()

  # confM = confusion_matrix(char_labels,Ypred)
  # io.imshow(confM)
  # plt.title('Confusion Matrix')
  # io.show()


def proximity(bbox, ground_truth_mid, threshold):

    # Calculate the center of the bounding box
    mid_x = (bbox[1] + bbox[3]) / 2  # Average of min_col and max_col
    mid_y = (bbox[0] + bbox[2]) / 2  # Average of min_row and max_row

    mid = np.array([[mid_x, mid_y]])

    # Calculate the distance between the mid center and the ground truth center
    distance = cdist(mid, [ground_truth_mid])


    return distance[0][0] <= threshold

def recognition_rate(bound_box, recognized_chars, ground_truth_locations, ground_truth_classes, threshold):

    correct_recognitions = 0

    # Loop through each detected character and its recognized character
    for bbox, recognized_char in zip(bound_box, recognized_chars):
        for ground_truth_mid, ground_truth_char in zip(ground_truth_locations, ground_truth_classes):

            if proximity(bbox, ground_truth_mid, threshold) and recognized_char == ground_truth_char:
                correct_recognitions += 1
                break  # No need to check remaining ground truth characters for this detection


    recognition_rate = correct_recognitions / len(ground_truth_classes)

    return recognition_rate



def test_data(test_path, normalized_db, training_std, training_mean, char_label, ground_truth_classes,ground_truth_locations, display = True):
    binary_thresh = 200
    noise_thresh = 9
    test_features = []
    boundingboxs = []
    recognized_letters = []  # Store recognized letters

    # print(img.shape)
    #----------------------------------------------------------------
    # io.imshow(img)
    # plt.title('Original Image')
    # io.show()
    #----------------------------------------------------------------
    img = io.imread(test_path)

    img_binary = read_and_binarize(test_path, binary_thresh)

    selem = square(2)
    img_binary = dilation(img_binary, selem)


    #----------------------------------------------------------------
    io.imshow(img_binary)
    plt.title('Binary Img')
    io.show()

    #-----------------------------------------------------------------
    img_label = label(img_binary, background = 0)

    # io.imshow(img_label)
    # plt.title("labled Img")
    # io.show()
    # print(np.amax(img_label))
    regions = regionprops(img_label)
    # io.imshow(img_binary)

    for props in regions:
      minr, minc, maxr, maxc = props.bbox
      if (maxr - minr) > noise_thresh and (maxc - minc) > noise_thresh:
        roi = img_binary[minr:maxr, minc:maxc]
        m = moments(roi)
        cc = m[0, 1] / m[0, 0]
        cr = m[1, 0] / m[0, 0]
        mu = moments_central(roi, center=(cr, cc))
        nu = moments_normalized(mu)
        hu = moments_hu(nu)
        test_features.append(hu)
        boundingboxs.append((minr, minc, maxr, maxc))


    normalized_test_features = (test_features - training_mean) / training_std
    D = cdist(normalized_test_features, normalized_db )
    D_index = np.argmin(D, axis = 1)



    for i in range(len(D_index)):

        nearest_neighbor_index = D_index[i]
        nearest_neighbor_class = char_label[nearest_neighbor_index]

        recognized_letter = chr(nearest_neighbor_class + ord('a') -1)
        recognized_letters.append(recognized_letter)


    recognized_letters = np.array(recognized_letters)
    print("recongnized", recognized_letters )
    print("recongnized", len(recognized_letters) )



    rr  = recognition_rate(boundingboxs, recognized_letters, ground_truth_locations,ground_truth_classes, 12)
    print(f"Recognition : {rr * 100: .2f}%")

    num_components = np.amax(img_label)
    print(f"Number of Connected Components in {test_path}: {num_components}")

    if display:
        io.imshow(img_binary)
        ax = plt.gca()

        for i, (minr, minc, maxr, maxc) in enumerate(boundingboxs):
            ax.add_patch(Rectangle((minc, minr), maxc - minc, maxr - minr, fill=False, edgecolor='red', linewidth=1))
            plt.text(maxc, minr, f'{recognized_letters[i]}', color='red', fontsize=8, verticalalignment='bottom')

        plt.title('Test Recognition')
        plt.show()


    return recognized_letters



pkl_file = open('test_gt_py3.pkl', 'rb')
mydict = pickle.load(pkl_file)
pkl_file.close()
classes = mydict[b'classes']
locations = mydict[b'locations']

# print(len(classes))

#training
image_paths = ['a.bmp', 'd.bmp', 'm.bmp', 'n.bmp', 'o.bmp', 'p.bmp', 'q.bmp', 'r.bmp', 'u.bmp', 'w.bmp']
training_features, training_char_labels, training_std, training_mean  = training_data(image_paths)
recongnition_training(training_features, training_char_labels)


# #recongnition
test_path = 'test.bmp'
recongnized_label_test = test_data(test_path, training_features, training_std, training_mean, training_char_labels, classes, locations)





